## 大模型相关知识整理

#### 一、熵

在机器学习和统计学中，熵是一种信息论的度量，表示系统的随机性或不确定性。**熵越高，代表不确定性越高。**

* **交叉熵（Cross-Entropy）**

​	衡量了实际标签与预测概率分布之间的差异，交叉熵损失函数在机器学习和深度学习中被广泛应用于训练分类模型，如逻辑回归、神经网络等。

​	具体的，对于一个K分类任务，假设模型的输出是一个概率分布$\mathbf{p} = [p_1, p_2, \ldots, p_K]$，其中 $p_i$ 是模型预测样本属于类别 i的概率。实际的标签用一个独热编码向量 $\mathbf{y} = [y_1, y_2, \ldots, y_K]$表示(0或1),交叉熵损失函数$\mathbf{L}$为：
$$
\mathbf{L}(y,p)=-\sum_{i=1}^{K}y_ilog(p_i)
$$

* **预测熵（Predictive Entropy）**

​	一种衡量预测模型不确定性的指标。如果模型对某一类别的预测概率非常高（接近1），而对其他类别的预测概率非常低（接近0），那么预测熵会很低，表示模型对其预测结果非常有信心。

​	具体的，假设模型的输出是一个概率分布$\mathbf{p} = [p_1, p_2, \ldots, p_K]$，其中 $p_i$ 是模型预测样本属于类别 i的概率。预测熵 $H(\mathbf{p})$定义为：
$$
\mathbf{H}(p)=-\sum_{i=1}^{K}p_ilog(p_i)
$$

#### 二、大模型理论（LLMs）

https://arxiv.org/pdf/2401.01286

###### 2.1 大模型架构

[深度学习进阶篇[1\]：Transformer模型原理;应用详解 - Heywhale.com](https://www.heywhale.com/mw/project/646d809b8fe9066e5c0d9eee)

目前，大型语言模型主要以Transformer架构作为基础，包含Encoder和Decoder两部分，每部分都是由多个相同的block层连接在一起，而每个block layer又包含自主意力层和前馈神经网络层。

* ***自注意力层（Self-Attention）***  

​	自主意力层是Transformer架构中的核心机制，相比于之前的RNN等序列网络，自注意力层能够并行高效的处理文本数据，并且能够捕获嵌入序列中的上下文信息。
$$
H = AAT(Q,K,V)=Softmax(\frac{QK^T}{\sqrt{d_k}})V
$$
其中Q，K，V分别代表查询，健，值。通俗来讲，自注意力机制的思想就是，当encoder某个位置的编码表示（语义空间）时，会根据查询与每个位置的**键**的关系计算每个位置的***值***的考虑权重，从而综合编码该位置的语义表示。

* ***前馈神经网络（FFN）***

​	FFN将从自注意力层得到的向量再投影到一个更大的空间，从而更方便地提取需要的信息（使用 Relu 激活函数），最后再投影回 token 向量原来的空间。***借鉴 SVM 来理解：SVM 对于比较复杂的问题通过将特征其投影到更高维的空间使得问题简单到一个超平面就能解决。***FFN包含两层的线性层：
$$
FFN(x)=ReLU(x\cdot w_1+b_1)\cdot w_2+b2
$$
此外，值得注意的是，现有的生成式大模型往往仅使用decoder层，采用掩码注意力层编码，并且每次只编码当前位置和其之前的token的语义信息，再将输出的token拼接到输入中，然后不断循环输出。

###### 2.2 大模型知识存储机制（Knowledge storge）

#### 三、强化学习概述（reinforce-learning）

#### 四、大模型技术报告

###### 4.1 llama3.1 report

大模型的训练过程分为pre-training和post-training两阶段:

* pre-training：利用大规模语料库对模型进行next-token预测，在预训练阶段模型学到了语言结构和事实知识。LLama3.1 利用15.6T tokens和8K的窗口长度进行了预训练。
* post-training： 预训练语言模型对语言有丰富的理解，但它还不能遵循指令或按照我们期望的方式回答。为此后训练阶段会进行几轮的微调，每轮都涉及对指令调整数据的监督微调 (SFT) 和直接偏好优化（DPO）。

***一、 Pre-training***

预训练阶段需要解决的主要问题有：（1） 预训练语料库的整合和过滤；（2） 模型架构的设置以及合适的参数选择；（3） 大规模预训练技术的开发

***1、 预训练数据***：

1. 网络数据管理：使用的大部分数据来自于网络，需要将网页上的文本数据提取出来，并进行过滤、清洗、和去重。此外，还需要使用合理的方法提取专门的领域数据（math，code）

2. 数据混合比例：为了获得高质量的语言模型，必须仔细确定预训练数据组合中不同数据源的比例。我们确定这种数据组合的主要工具是知识分类和缩放定律实验。

***2、 模型架构***：

模型架构与前面的llama没有区别，值得注意的是更为可靠的训练scaling law，即给定训练预算，确定合适的训练tokens和训练参数，使得模型在下游任务上表现最佳。

> [!IMPORTANT]
>
> Scaling Law是指模型的性能与计算量、模型参数量和数据大小三者之间存在的关系。具体来说，当不受其他因素制约时，模型的性能与这三者呈现幂律关系。这意味着，增加计算量、模型参数量或数据大小都可能会提升模型的性能，但是提升的效果会随着这些因素的增加而递减。

***3、 训练策略***：

用于预训练 Llama 3 405B 的配方包括三个主要阶段：（1）初始预训练、（2）长上下文预训练和（3）退火。



***二、Post-training***

![image-20240812163823347](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240812163823347.png)

![image-20240812163604437](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240812163604437.png)

***1、 后训练数据***：

