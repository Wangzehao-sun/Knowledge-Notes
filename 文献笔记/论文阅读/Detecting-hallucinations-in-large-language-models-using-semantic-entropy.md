---
tags: []
parent: ""
collections:
    - 'Knowledge Hallucination'
$version: 744
$libraryID: 1
$itemKey: U6KGDPFM

---
## Detecting hallucinations in large language models using semantic entropy

#### ℹ️基本信息

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **期刊: Nature**（发表年份: 2024）**作者:****机构: 牛津大学**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| **摘要:**<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F14711266%2Fitems%2FCFBX43RB%22%2C%22pageLabel%22%3A%22625%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B217.323806762%2C603.884524902%2C523.0776118160001%2C614.0742760740001%5D%2C%5B217.320611816%2C590.888524902%2C538.9986118160008%2C599.852524902%5D%2C%5B217.32061181600005%2C577.884524902%2C543.4274123530002%2C588.0742760740001%5D%2C%5B217.32141235300003%2C564.888524902%2C549.2585123530008%2C573.852524902%5D%2C%5B217.32141235300003%2C551.884524902%2C541.0984992670002%2C562.0742760740001%5D%2C%5B217.32348883599997%2C538.884524902%2C546.0510000000003%2C549.0742760740001%5D%2C%5B217.32600000000002%2C525.884524902%2C560.858611328%2C536.0742760740001%5D%2C%5B217.319622047%2C512.888524902%2C555.6071220470008%2C521.852524902%5D%2C%5B217.319622047%2C499.892524902%2C553.3535220470004%2C508.856524902%5D%2C%5B217.319622047%2C486.896524902%2C560.237622043563%2C495.860524902%5D%2C%5B217.319622047%2C473.90052490200003%2C560.2646220470007%2C482.864524902%5D%2C%5B217.319622047%2C460.90452490200005%2C554.3516220470007%2C469.86852490200005%5D%2C%5B217.319622047%2C447.90852490200007%2C546.5432220435623%2C456.87252490200007%5D%2C%5B217.319622047%2C434.9125249020001%2C539.9669220538765%2C443.8765249020001%5D%2C%5B217.319622047%2C421.9165249020001%2C552.5066220470009%2C430.8805249020001%5D%2C%5B217.319622047%2C408.9205249020001%2C561.3005220470012%2C417.8845249020001%5D%2C%5B217.319622047%2C395.92452490200014%2C543.4616220470006%2C404.88852490200014%5D%2C%5B217.319622047%2C382.92852490200016%2C531.9146220470006%2C391.89252490200016%5D%2C%5B217.319622047%2C369.9325249020002%2C268.88062204700014%2C378.8965249020002%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14711266%2Fitems%2FQUKXKBXR%22%5D%2C%22locator%22%3A%22625%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/CFBX43RB?page=1">“Large language model (LLM) systems, such as ChatGPT1 or Gemini2, can show impressive reasoning and question-answering capabilities but often ‘hallucinate’ false outputs and unsubstantiated answers3,4. Answering unreliably or without the necessary information prevents adoption in diverse fields, with problems including fabrication of legal precedents5 or untrue facts in news articles6 and even posing a risk to human life in medical domains such as radiology7. Encouraging truthfulness through supervision or reinforcement has been only partially successful8. Researchers need a general method for detecting hallucinations in LLMs that works even with new and unseen questions to which humans might not know the answer. Here we develop new methods grounded in statistics, proposing entropy-based uncertainty estimators for LLMs to detect a subset of hallucinations—confabulations—which are arbitrary and incorrect generations. Our method addresses the fact that one idea can be expressed in many ways by computing uncertainty at the level of meaning rather than specific sequences of words. Our method works across datasets and tasks without a priori knowledge of the task, requires no task-specific data and robustly generalizes to new tasks not seen before. By detecting when a prompt is likely to produce a confabulation, our method helps users understand when they must take extra care with LLMs and opens up new possibilities for using LLMs that are otherwise prevented by their unreliability.”</a></span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F14711266%2Fitems%2FQUKXKBXR%22%5D%2C%22locator%22%3A%22625%22%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/QUKXKBXR">“Detecting hallucinations in large language models using semantic entropy | Nature”, p. 625</a></span>)</span> |
| \*\*Local Link: \*\*[Detecting hallucinations in large language models .pdf](zotero://open-pdf/0_CFBX43RB)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |

#### 💡一、研究内容

<span style="color: rgb(54, 60, 66)"><span style="background-color: rgb(255, 255, 255)">大型语言模型（LLMs）在生成文本时出现的“幻觉”现象，即模型生成不合理或与给定信息不符的内容。研究如何利用语义熵作为一种工具来检测知识幻觉和提高LLM生成文本的可靠性。</span></span>

#### 📜二、研究背景

<span style="color: rgb(54, 60, 66)">大模型取得了令人印象深刻的效果，但依然存在知识幻觉-----></span>

<span style="color: rgb(54, 60, 66)">回答不可靠严重限制了LLMs在高严谨领域的应用---------></span>

<span style="color: rgb(54, 60, 66)">监督学习、强化学习取得了一定的成功-----------></span>

<span style="color: rgb(54, 60, 66)">依然需要一种有效的方法检测幻觉，即使对于人类没见过或不知道答案的问题-------></span>

<span style="color: rgb(54, 60, 66)">为此提出了基于语义熵的不确定检测器，用于检测幻觉------------></span>

<span style="color: rgb(54, 60, 66)">该方法相比之前克服了语义多样性的问题，且不需要先验知识。</span>

#### 🔬三、主要方法

1、方法流程：

![\<img alt="image-20240827104203146" data-attachment-key="Z8Q6IP53" width="888" height="273" src="attachments/Z8Q6IP53.png" ztype="zimage">](attachments/Z8Q6IP53.png)

*   设置模型的推理生成参数（temperature，top-k），采样模型对问题的多个输出回答
*   将输出根据语义进行分类（根据是否相互语义蕴含分为一类，使用某种NLI模型完成）
*   根据语义类别计算语义不确定性（语义熵）

2、具体实例：

![\<img alt="image-20240827104237759" data-attachment-key="N3HV23FQ" width="866" height="548" src="attachments/N3HV23FQ.png" ztype="zimage">](attachments/N3HV23FQ.png)

#### 🚩四、实验结果

#### 📌五、知识点

> \[!IMPORTANT]
>
> 大模型幻觉定义：大模型生成无意义或不忠于源内容的输出，LLMs generating “content that is nonsensical or unfaithful to the provided source content”
>
> 本篇文章针对模型幻觉中的虚构问题，提出了基于语义熵的检测方法（熵高意味着不确定性高，相比于传统的基于token的熵计算，语义熵能够克服语义多样性的问题）

#### 🔬六、思考
