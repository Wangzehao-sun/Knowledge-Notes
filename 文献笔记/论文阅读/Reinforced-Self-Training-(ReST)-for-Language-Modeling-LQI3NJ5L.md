---
tags: []
parent: 'Reinforced Self-Training (ReST) for Language Modeling'
collections:
    - self-improvement
$version: 12070
$libraryID: 1
$itemKey: LQI3NJ5L

---
## Reinforced Self-Training (ReST) for Language Modeling

#### â„¹ï¸åŸºæœ¬ä¿¡æ¯

| <!-- --> |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **æœŸåˆŠ:**\*\*\*\*\*\*ï¼ˆå‘è¡¨å¹´ä»½:**2023**ï¼‰**ä½œè€…:**Caglar Gulcehre; Tom Le Paine; Srivatsan Srinivasan; Ksenia Konyushkova; Lotte Weerts; Abhishek Sharma; Aditya Siddhant; Alex Ahern; Miaosen Wang; Chenjie Gu; Wolfgang Macherey; Arnaud Doucet; Orhan Firat; Nando de Freitas**æœºæ„:**deepmind                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| \*\*æ‘˜è¦: \*\**Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.* |
| \*\*Local Link: \*\*[Gulcehre ç­‰ - 2023 - Reinforced Self-Training (ReST) for Language Modeling.pdf](zotero://open-pdf/0_NZ42HE6I)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |


#### ğŸ’¡ä¸€ã€ç ”ç©¶å†…å®¹

ä¸€ç§ç®€å•çš„ç®—æ³•ä½¿ LLM ä¸äººç±»åå¥½å¯¹é½ [ReST](https://zhida.zhihu.com/search?content_id=232925629\&content_type=Article\&match_order=1\&q=ReST\&zhida_source=entity)ï¼ˆReinforced Self-Trainingï¼‰ï¼ŒReST é€šè¿‡ç”Ÿæˆå’Œä½¿ç”¨ç¦»çº¿æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»è€Œä½¿å¾— LLM ä¸äººç±»åå¥½ä¿æŒä¸€è‡´ã€‚

ç»™å®šä¸€ä¸ªåˆå§‹ LLM ç­–ç•¥ï¼ŒReST èƒ½å¤Ÿæ ¹æ®è¯¥ç­–ç•¥ç”Ÿæˆæ•°æ®é›†ï¼Œç„¶åè¯¥æ•°æ®é›†åŸºäºç¦»çº¿ RL ç®—æ³•è¢«åè¿‡æ¥æé«˜ LLM ç­–ç•¥ã€‚ReST æ¯”å…¸å‹çš„åœ¨çº¿ RLHF æ–¹æ³•æ›´æœ‰æ•ˆï¼Œå› ä¸ºè®­ç»ƒæ•°æ®é›†æ˜¯ç¦»çº¿ç”Ÿæˆçš„ï¼Œè¿™å…è®¸æ•°æ®é‡ç”¨ã€‚

ReST ç®—æ³•å°†å…¸å‹ RL pipeline çš„æ•°æ®é›†å¢é•¿ï¼ˆGrowï¼‰å’Œç­–ç•¥æ”¹è¿›ï¼ˆImproveï¼‰è§£è€¦æˆä¸¤ä¸ªå•ç‹¬çš„ç¦»çº¿é˜¶æ®µã€‚

#### ğŸ“œäºŒã€ç ”ç©¶èƒŒæ™¯

#### ğŸ”¬ä¸‰ã€ä¸»è¦æ–¹æ³•

#### ğŸš©å››ã€å®éªŒç»“æœ

#### ğŸ“Œäº”ã€çŸ¥è¯†ç‚¹

<https://zhuanlan.zhihu.com/p/693582342>

**online/offline** è§£å†³çš„é—®é¢˜ï¼š**â€œæ˜¯å¦å¯ä»¥æŒç»­äº¤äº’æ”¶é›†æ–°æ•°æ®â€**

*   **åœ¨çº¿å¼ºåŒ–å­¦ä¹ **ï¼šåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæ™ºèƒ½ä½“ç›´æ¥ä¸ç¯å¢ƒå®æ—¶äº¤äº’ï¼Œæ¯ä¸€æ­¥é€‰æ‹©åŠ¨ä½œã€æ¥æ”¶ç¯å¢ƒåé¦ˆï¼ˆå¥–åŠ±å’Œä¸‹ä¸€ä¸ªçŠ¶æ€ï¼‰ï¼Œå¹¶ç«‹å³ç”¨è¿™äº›æ–°é²œæ•°æ®æ›´æ–°å…¶ç­–ç•¥æˆ–ä»·å€¼å‡½æ•°ã€‚è¿™æ„å‘³ç€å­¦ä¹ ç­–ç•¥ä¼šç›´æ¥å½±å“åˆ°å®é™…è¡Œä¸ºï¼Œå¹¶ä¸”ç¯å¢ƒéœ€è¦æ˜¯å¯äº¤äº’çš„ã€‚

*   **ç¦»çº¿å¼ºåŒ–å­¦ä¹ **ï¼šäº‹å…ˆä»ä¸€ä¸ªå›ºå®šçš„æ•°æ®é›†ï¼ˆé€šå¸¸æ˜¯ä¹‹å‰äº¤äº’äº§ç”Ÿçš„ï¼‰ä¸­å­¦ä¹ ï¼Œä¸ä¸ç¯å¢ƒå®æ—¶äº’åŠ¨ã€‚è¿™ä¸ªæ•°æ®é›†å¯ä»¥æ˜¯é€šè¿‡ä¸“å®¶æ¼”ç¤ºã€å†å²è®°å½•æˆ–å…¶ä»–ä»£ç†çš„è¡Œä¸ºæ”¶é›†çš„ã€‚ç¦»çº¿å­¦ä¹ çš„ç›®æ ‡æ˜¯ä»è¿™äº›é™æ€æ•°æ®ä¸­æœ€å¤§åŒ–å­¦ä¹ æ•ˆç‡ï¼Œè€Œæ— éœ€è¿›ä¸€æ­¥æ¢ç´¢ç¯å¢ƒã€‚

#### ğŸ”¬å…­ã€æ€è€ƒ
